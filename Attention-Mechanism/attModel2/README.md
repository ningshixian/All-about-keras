# LSTM_Attention

GitHub 项目

[Keras Attention Mechanism](https://github.com/philipperemy/keras-attention-mechanism)

*Example: Attention block*

- `SINGLE_ATTENTION_VECTOR = False`
- **Attention defined per time series (each TS has its own attention)**

![](attention.png)



- `SINGLE_ATTENTION_VECTOR = True`

**Attention shared across all the time series**
[![img](https://github.com/philipperemy/keras-attention-mechanism/raw/master/assets/graph_single_attention.png)](https://github.com/philipperemy/keras-attention-mechanism/blob/master/assets/graph_single_attention.png)

## 